epoch: train_acc1 train_acc2 test_acc1 test_acc2 test_f1 test_f2 
0: 0 0 0.5120259019426457 0.09954407294832827 0.4357282472820004 0.03842504204129117 
1: 0.8836613166623 0.631612917272056 0.9472710453283997 0.833080040526849 0.9464972765423159 0.6520967837848364 
2: 0.9718347875083365 0.8485641479492188 0.954209065679926 0.8449848024316109 0.9536986381379775 0.7436965249433881 
3: 0.9761708887611947 0.8913854273354135 0.9481961147086031 0.8601823708206687 0.9474240055584506 0.7724840816524051 
4: 0.9777482195598323 0.9123063436368617 0.9565217391304348 0.871580547112462 0.9560413984523166 0.7853086078935029 
5: 0.9801012364829459 0.921964877989234 0.9518963922294172 0.8617021276595744 0.951063829787234 0.7723909017232317 
6: 0.9790069766160918 0.9322789820229135 0.9292321924144311 0.8475177304964538 0.9288473580022039 0.7612570023228 
7: 0.9808619429425496 0.9365761919719416 0.9597594819611471 0.85612968591692 0.9591917849856992 0.7888393102638395 
8: 0.9802731769840892 0.9424523144233518 0.9481961147086031 0.8513171225937184 0.9477121473208694 0.7916893286430885 
9: 0.9831360607612424 0.9465038950850324 0.956059204440333 0.8708206686930091 0.9554970050019556 0.8015126246208891 
10: 0.9832361733041158 0.9502238762087938 0.9417206290471786 0.8503039513677811 0.940981177204659 0.7985888728799123 
11: 0.9836811903046399 0.9564623018590416 0.9505087881591119 0.8720871327254306 0.9498965048147947 0.8074523887375802 
12: 0.9845825753560881 0.9567985534667969 0.9528214616096207 0.8738601823708206 0.9519077776614675 0.8038909918666832 
13: 0.9846081617401867 0.9614799313428926 0.9565217391304348 0.8703140830800405 0.9559974260308651 0.7971064087062317 
14: 0.9856246389993807 0.9633334090070027 0.9495837187789085 0.8657548125633232 0.9489386688969805 0.7953454307081416 
